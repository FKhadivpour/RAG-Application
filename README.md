# ğŸ’¡ RAG Knowledge Assistant

A Retrieval-Augmented Generation (RAG) application that leverages vector databases and large language models to provide accurate, context-aware responses based on specific knowledge domains.

## Overview

This repository implements a complete RAG pipeline with a user-friendly web interface. The system retrieves relevant information from a vector database containing embedded documents and uses this context to generate accurate responses through a large language model.

## Features

- **Document Processing Pipeline**: Ingest, chunk, and embed documents from various sources
- **Vector Database Integration**: Store and efficiently query document embeddings
- **Semantic Search**: Find the most relevant context for user queries
- **LLM Integration**: Generate contextually accurate responses using retrieved information
- **Web Interface**: User-friendly UI for interacting with the RAG system
- **API Endpoints**: RESTful API for programmatic access to the RAG pipeline
- **Performance Metrics**: Evaluation tools to measure retrieval and generation quality

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚
â”‚  Data Ingestion â”‚â”€â”€â”€â”€â–¶â”‚ Vector Database â”‚â”€â”€â”€â”€â–¶â”‚  LLM Interface  â”‚
â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â–²                       â”‚
        â”‚                       â”‚                       â”‚
        â–¼                       â”‚                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚
â”‚ Text Processing â”‚     â”‚  Query Engine   â”‚â—€â”€â”€â”€â”€â”‚   Web Server    â”‚
â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Dataset

This project uses the [ArXiv Dataset](https://www.kaggle.com/datasets/Cornell-University/arxiv) containing scientific papers across various domains. The dataset provides rich, technical content perfect for demonstrating RAG capabilities in specialized knowledge retrieval.

## Technologies Used

- **Backend**: Python, FastAPI
- **Vector Database**: Chroma
- **Embeddings**: Sentence-Transformers
- **LLM Integration**: OpenAI API (with option for local models)
- **Frontend**: React with TypeScript
- **Containerization**: Docker
- **Testing**: Pytest



## Getting Started

### Prerequisites

- Python 3.9+
- Node.js 16+
- Docker (optional)

### ğŸ› ï¸ Installation

1. Clone the repository
```bash
git clone https://github.com/fkhadivpour/RAG-Application.git
```

2. Set up the Python environment
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

3. Set up environment variables
```bash
cp .env.example .env
# Edit .env with your API keys and configuration
```

```env
HOST=127.0.0.1
PORT=8000
DATA_DIR=data/raw
OUTPUT_DIR=data/processed
VECTOR_STORE_DIR=data/vector_store
EMBEDDING_MODEL_NAME=all-MiniLM-L6-v2
OPENAI_API_KEY=your-openai-key-here
OPENAI_API_BASE=https://api.openai.com/v1
```

3. **Process Data** (one-time to populate vector store):

```bash
python main.py --process-data
```

4. **Start Backend Server**:

```bash
python main.py
```

Backend will run on:
```
http://127.0.0.1:8000
```

---

## ğŸ’¾ Frontend Setup (React)

1. **Go to frontend folder**:

```bash
cd frontend
```

2. **Install dependencies**:

```bash
npm install
```

3. **Start Frontend Server**:

```bash
npm start
```

Frontend will open at:
```
http://localhost:3000
```

Frontend will automatically proxy API requests to backend (`http://localhost:8000`).

---

## ğŸš€ Usage Flow

- Open [http://localhost:3000](http://localhost:3000)
- Type a query related to your documents (e.g., "What is machine learning?")
- Click "Search"
- See AI-generated answer based on retrieved document context!

---




## ğŸ“‚ Project Structure

```
RAG-Application/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # Raw ArXiv JSON documents
â”‚   â”œâ”€â”€ processed/         # Processed chunks
â”‚   â””â”€â”€ vector_store/      # ChromaDB persisted vectors
â”œâ”€â”€ docker/                # (empty) - reserved for Docker configs
â”œâ”€â”€ notebooks/             # (empty) - reserved for experiments
â”œâ”€â”€ scripts/               # (empty) - reserved for automation scripts
â”œâ”€â”€ src/                   # Python backend source code
â”‚   â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ data_processing/
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ vector_store/
â”‚   â””â”€â”€ evaluation/        # (optional future) evaluation code
â”œâ”€â”€ frontend/              # React frontend application
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ index.html
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.js
â”‚   â”‚   â”œâ”€â”€ index.js
â”‚   â”‚   â”œâ”€â”€ App.css
â”‚   â”‚   â””â”€â”€ index.css
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ .env               # Frontend-specific environment
â”œâ”€â”€ .env                   # Backend-specific environment
â”œâ”€â”€ main.py                # Backend entry point
â””â”€â”€ README.md              # (this file)
```

---

## ğŸ“‹ Notes

- Download the ArXiv dataset json file from kaggle into data/raw folder.
- Backend and Frontend must be running simultaneously in separate terminals.

---

## ğŸ“ˆ Future Improvements

- Add Docker support
- Add unit tests inside `/tests/`
- Improve frontend UI/UX
- Support PDF and DOCX ingestion

---

## ğŸ“ Quick Developer Commands

| Action | Command |
|:-------|:--------|
| Process documents | `python main.py --process-data` |
| Start backend server | `python main.py` |
| Start frontend server | `npm start` (inside `frontend/`) |
| Fix npm vulnerabilities | `npm audit fix --force` (optional) |

---

# âœ… Full Stack Ready!

- FastAPI + ChromaDB + OpenAI + React.js
- Fully modular and professional RAG application
- Easy to extend, deploy, and scale

---

